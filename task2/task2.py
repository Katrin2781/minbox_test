# -*- coding: utf-8 -*-
"""task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BYLpc57zs3xDZnrra0tVxFE1EiYYl1F2
"""

! pip install pyspark py4j

from pyspark.sql import SparkSession

spark = SparkSession.builder\
        .master("local[*]")\
        .appName('Task2')\
        .getOrCreate()

from pyspark.sql.types import *
schema_prod = [StructField('id',IntegerType(),True),
               StructField('pr_name', StringType(),True),
               StructField('pr_count',IntegerType(),True)]
final_struc_pr = StructType(fields = schema_prod)

schema_category = [StructField('id',IntegerType()),
               StructField('category', StringType(),True),]
final_struc_category = StructType(fields = schema_category)

schema_linkCategory = [StructField('id',IntegerType()),
                       StructField('id_product', IntegerType(),True),
                       StructField('id_category',IntegerType(),True)]
final_struc_link = StructType(fields = schema_linkCategory)

df_product = spark.read.csv(
    'product.csv',
    sep=';',
    header=True,
    schema = final_struc_pr
)
df_product.show(5)

df_category = spark.read.csv(
    'Categories.csv',
    sep=';',
    header=True,
    schema = final_struc_category
)
df_category.show(5)

df_link = spark.read.csv(
    'LinkCategories.csv',
    sep=';',
    header=True,
    schema = final_struc_link
)
df_link.show(5)

df_product.createOrReplaceTempView('Product')
df_category.createOrReplaceTempView('Category')
df_link.createOrReplaceTempView('Link')

joinDF = spark.sql('select  p.pr_name, c.category from category c full join link l on l.id_category==c.id full join product p on p.id==l.id_product').show()